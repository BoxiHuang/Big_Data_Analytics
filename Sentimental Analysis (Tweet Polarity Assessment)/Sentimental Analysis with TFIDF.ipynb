{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "GF3llooZxRFL",
    "outputId": "fe0b896d-b48f-4ca9-d512-c609054ef38f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n",
      "tweets.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Need to install pyspark\n",
    "# if pyspark is already installed, will print a message indicating pyspark already isntalled\n",
    "pip install pyspark\n",
    "\n",
    "# Download tweets.csv from github\n",
    "# If the tweets.csv file does not exist in the colab environment\n",
    "if [[ ! -f ./tweets.csv ]]; then \n",
    "   # download tweets.csv file from github and save it in this colab environment instance\n",
    "   wget https://raw.githubusercontent.com/wewilli1/ist718_data/master/tweets.csv   \n",
    "fi\n",
    "\n",
    "# vefify tweets.csv exits in the colab env - should not print an error message\n",
    "ls tweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nMmYj81PxRFP"
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "B2B2Fy7-xRFS",
    "outputId": "66790199-c7b8-49c5-dacd-3c36f7f7586c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(target='4', id='1467822272', date='Mon Apr 06 22:22:45 PDT 2009', flag='NO_QUERY', user='ersle', text='I LOVE @Health4UandPets u guys r the best!! '),\n",
       " Row(target='4', id='1467822273', date='Mon Apr 06 22:22:45 PDT 2009', flag='NO_QUERY', user='becca210', text='im meeting up with one of my besties tonight! Cant wait!!  - GIRL TALK!!'),\n",
       " Row(target='4', id='1467822283', date='Mon Apr 06 22:22:46 PDT 2009', flag='NO_QUERY', user='Wingman29', text='@DaRealSunisaKim Thanks for the Twitter add, Sunisa! I got to meet you once at a HIN show here in the DC area and you were a sweetheart. '),\n",
       " Row(target='4', id='1467822287', date='Mon Apr 06 22:22:46 PDT 2009', flag='NO_QUERY', user='katarinka', text='Being sick can be really cheap when it hurts too much to eat real food  Plus, your friends make you soup'),\n",
       " Row(target='4', id='1467822293', date='Mon Apr 06 22:22:46 PDT 2009', flag='NO_QUERY', user='_EmilyYoung', text='@LovesBrooklyn2 he has that effect on everyone ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example code to read the downloaded tweets.csv file on colab\n",
    "tweets_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"tweets.csv\")\n",
    "tweets_df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5FeY3L8x5IN"
   },
   "source": [
    "What problems did you have with colab? Your comments here:\n",
    "    \n",
    "I do not have major problem with colab and I have a great experience using this platform. However, one concern that I have is that if we train/test model with heavy weight operations (Ex: Large data set), I am worry that the datafile recycling on Google Colab might have a negative impact with the model training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XWTuJqnyxRFY"
   },
   "outputs": [],
   "source": [
    "# Do not delete or change this cell\n",
    "\n",
    "enable_grid = True\n",
    "\n",
    "# grading import statements\n",
    "%matplotlib inline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "import os\n",
    "\n",
    "# Define a function to determine if we are running on data bricks\n",
    "# Return true if running in the data bricks environment, false otherwise\n",
    "def is_databricks():\n",
    "    # get the databricks runtime version\n",
    "    db_env = os.getenv(\"DATABRICKS_RUNTIME_VERSION\")\n",
    "    \n",
    "    # if running on data bricks\n",
    "    if db_env != None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Define a function to read the data file.  The full path data file name is constructed\n",
    "# by checking runtime environment variables to determine if the runtime environment is \n",
    "# databricks, or a student's personal computer.  The full path file name is then\n",
    "# constructed based on the runtime env.\n",
    "# \n",
    "# Params\n",
    "#   data_file_name: The base name of the data file to load\n",
    "# \n",
    "# Returns the full path file name based on the runtime env\n",
    "#\n",
    "# Correct Usage Example (pass ONLY the full file name):\n",
    "#   file_name_to_load = get_training_filename(\"sms_spam.csv\") # correct - pass ONLY the full file name  \n",
    "#   \n",
    "# Incorrect Usage Example\n",
    "#   file_name_to_load = get_training_filename(\"/sms_spam.csv\") # incorrect - pass ONLY the full file name\n",
    "#   file_name_to_load = get_training_filename(\"sms_spam.csv/\") # incorrect - pass ONLY the full file name\n",
    "#   file_name_to_load = get_training_filename(\"c:/users/will/data/sms_spam.csv\") incorrect -pass ONLY the full file name\n",
    "def get_training_filename(data_file_name):    \n",
    "    # if running on data bricks\n",
    "    if is_databricks():\n",
    "        # build the full path file name assuming data brick env\n",
    "        full_path_name = \"dbfs:/FileStore/tables/%s\" % data_file_name\n",
    "    # else the data is assumed to be in the same dir as this notebook\n",
    "    else:\n",
    "        # Assume the student is running on their own computer and load the data\n",
    "        # file from the same dir as this notebook\n",
    "        full_path_name = data_file_name\n",
    "    \n",
    "    # return the full path file name to the caller\n",
    "    return full_path_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_CWPFkkxRFb"
   },
   "source": [
    "# Sentiment Analysis\n",
    "In this assignment, you will use the tweets.csv file to perform sentiment analysis. The tweets.csv file contains the following columns:\n",
    "- target: the polarity of the tweet (0 = negative, 4 = positive)\n",
    "- ids: The id of the tweet ( 2087)\n",
    "- date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "- flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "- user: the user that tweeted (robotickilldozr)\n",
    "- text: the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8AboFtBxRFb"
   },
   "source": [
    "# Qustion 1: (10 pts)\n",
    "Read tweets.csv into a spark dataframe named `tweets_df`.  Solutions that do not use `get_training_filename` will be heavily penalized.  Drop all columns except target and text.  Transform the target column such that a negative sentiment is equal to 0 and a positive sentiment is equal to 1.  Determine and print the percentage of positive and negative tweets in the dataframe such that it's easy for the graders to find and interpret your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "LiaXgmfGxRFc",
    "outputId": "c94ad8ef-3f43-4f27-e9f1-64fda483be0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------+-------------------+\n",
      "|target|Count based on polarity|Polarity percentage|\n",
      "+------+-----------------------+-------------------+\n",
      "|     1|                  50000|               50.0|\n",
      "|     0|                  50000|               50.0|\n",
      "+------+-----------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "import pyspark.sql.functions as fn \n",
    "from pyspark.sql.functions import col, when, size\n",
    "import os\n",
    "\n",
    "tweets_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(get_training_filename(\"tweets.csv\"))\n",
    "drop_col = ['id','date','flag','user']\n",
    "tweets_df = tweets_df.drop(*drop_col)\n",
    "tweets_df = tweets_df.withColumn(\"target\", when(col(\"target\") == 0, 0)\n",
    "                                 .when(col(\"target\") == 4, 1))\n",
    "tot = tweets_df.count()\n",
    "percent = tweets_df.groupBy('target').count().withColumnRenamed('count',\"Count based on polarity\").withColumn(\"Polarity percentage\", fn.col(\"Count based on polarity\")/tot *100)\n",
    "percent.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "Pl4yr1hYxRFo",
    "outputId": "862cb08a-ae64-42bb-b842-b7d2d280bb1b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       1       I LOVE @Health4UandPets u guys r the best!! \n",
       "1       1  im meeting up with one of my besties tonight! ...\n",
       "2       1  @DaRealSunisaKim Thanks for the Twitter add, S...\n",
       "3       1  Being sick can be really cheap when it hurts t...\n",
       "4       1    @LovesBrooklyn2 he has that effect on everyone "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 2)\n"
     ]
    }
   ],
   "source": [
    "# grading cell do not modify\n",
    "tweets_pd = tweets_df.toPandas()\n",
    "display(tweets_pd.head())\n",
    "print(tweets_pd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdftI6pexRFs"
   },
   "source": [
    "# Question 2: (10 pts)\n",
    "Pre-process the data by creating a pipeline named `tweets_pre_proc_pipe`. Your pipeline should tokenize, remove stop words, and do a TF-IDF transformation.  Fit and execute your pipeline, and create a new dataframe named `tweets_pre_proc_df`.  Print the shape of the resulting TF-IDF data such that it's easy for the graders to find and understand as num rows x num words. Based on the shape of the TF-IDF data, would you expect a logistic regression model to overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "EaGlReFdxRFs",
    "outputId": "972ca50e-aa01-4b75-c101-bbd34707c966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(num row x num word) : (100000, 13693)\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "import requests\n",
    "stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()\n",
    "\n",
    "#tokenizer = RegexTokenizer(minTokenLength=2).setInputCol('text').setOutputCol('words').setGaps(False).setPattern(\"\\\\p{L}+\")\n",
    "#tokenizer = RegexTokenizer().setInputCol('text').setOutputCol('words')\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "#remover = StopWordsRemover(inputCol='words', outputCol='words_clean')\n",
    "\n",
    "remover = StopWordsRemover()\\\n",
    "  .setStopWords(stop_words)\\\n",
    "  .setCaseSensitive(False)\\\n",
    "  .setInputCol(\"words\")\\\n",
    "  .setOutputCol(\"words_clean\")\n",
    "\n",
    "cv = CountVectorizer(minTF =1, minDF = 5, vocabSize = 2**17, inputCol='words_clean', outputCol=\"tf\")\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"tfidf\")\n",
    "\n",
    "# Pre-processing pipeline\n",
    "tweets_pre_proc_pipe = Pipeline(stages=[tokenizer,remover,cv,idf])\n",
    "\n",
    "# fit the model with tweets_df\n",
    "model = tweets_pre_proc_pipe.fit(tweets_df)\n",
    "tweets_pre_proc_df = model.transform(tweets_df)\n",
    "\n",
    "\n",
    "num_row = tweets_pre_proc_df.select('tf').count()\n",
    "#test = tweets_pre_proc_df.withColumn(\"word_count\", size(\"words_clean\"))\n",
    "#num_word = test.groupBy().sum(\"word_count\").collect()[0][0]\n",
    "num_word = len(model.stages[-2].vocabulary)\n",
    "print('(num row x num word) :', (num_row,  num_word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "B0kv-IGxxRFu",
    "outputId": "7671b523-4645-4ba3-924a-d793bee8fe92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>words_clean</th>\n",
       "      <th>tf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "      <td>[i, love, @health4uandpets, u, guys, r, the, b...</td>\n",
       "      <td>[love, @health4uandpets, u, guys, r, best!!]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "      <td>[im, meeting, up, with, one, of, my, besties, ...</td>\n",
       "      <td>[im, meeting, besties, tonight!, wait!!, , -, ...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(1.1265280578718189, 0.0, 0.0, 0.0, 0.0, 3.183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "      <td>[@darealsunisakim, thanks, for, the, twitter, ...</td>\n",
       "      <td>[@darealsunisakim, thanks, twitter, add,, suni...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "      <td>[being, sick, can, be, really, cheap, when, it...</td>\n",
       "      <td>[sick, really, cheap, hurts, eat, real, food, ...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(1.1265280578718189, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
       "      <td>[@lovesbrooklyn2, he, has, that, effect, on, e...</td>\n",
       "      <td>[@lovesbrooklyn2, effect]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  ...                                              tfidf\n",
       "0       1  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1       1  ...  (1.1265280578718189, 0.0, 0.0, 0.0, 0.0, 3.183...\n",
       "2       1  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3       1  ...  (1.1265280578718189, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4       1  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grading cell do not modify\n",
    "display(tweets_pre_proc_df.toPandas().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLNf_3NgxRFw"
   },
   "source": [
    "Your explanation here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SV0lHvTxRFx"
   },
   "source": [
    "Based on the shape of the TF-IDF data, I think the logistic regression model will be overfitted because we have a significantly larger number of features than the number of data within the dataset. And this number of data is prior to spliting into training, validation and testing set,too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOINu8VhxRFx"
   },
   "source": [
    "# Question 3: (10 pts)\n",
    "Since IDF considers a word's frequency across all documents in a corpus, you can use IDF as a form of inference.  Examine the documentation for the spark ML object that you used to create TF-IDF scores and learn how to extract the IDF scores for words in the corpus.  Create a pandas dataframe containing the 5 most important IDF scores named `most_imp_idf`.  Create another pandas dataframe containing the 5 least important IDF scores named `least_imp_idf`.  Each dataframe shall have 2 columns named `word` and `idf_score`.  Explain in words your interpretation of what the IDF scores mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sDAaOVGWxRFy"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# NEED TO COME BACK HERE\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Extract words and idf score\n",
    "word = model.stages[-2].vocabulary\n",
    "#print(len(word))\n",
    "idf = model.stages[-1].idf\n",
    "# Create panda dataframe\n",
    "word_idf_pd = pd.DataFrame({'word': word, 'idf_score': idf })\n",
    "max_value = word_idf_pd['idf_score'].max()\n",
    "most_imp_idf = word_idf_pd[word_idf_pd['idf_score']== max_value]\n",
    "#most_imp_idf = word_idf_pd.sort_values('idf_score', ascending=False).head(5)\n",
    "least_imp_idf = word_idf_pd.sort_values('idf_score', ascending=True).head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "OrtxkKEuxRF1",
    "outputId": "9ed29a36-7cdb-44ee-920d-96f3aa650812"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>idf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7853</th>\n",
       "      <td>tsk</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8196</th>\n",
       "      <td>but..</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>thks</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9164</th>\n",
       "      <td>(8)</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9185</th>\n",
       "      <td>broke,</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13688</th>\n",
       "      <td>suckss</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13689</th>\n",
       "      <td>prada</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13690</th>\n",
       "      <td>universe!</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13691</th>\n",
       "      <td>playin'</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13692</th>\n",
       "      <td>blended</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2085 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  idf_score\n",
       "7853         tsk   9.721176\n",
       "8196       but..   9.721176\n",
       "9121        thks   9.721176\n",
       "9164         (8)   9.721176\n",
       "9185      broke,   9.721176\n",
       "...          ...        ...\n",
       "13688     suckss   9.721176\n",
       "13689      prada   9.721176\n",
       "13690  universe!   9.721176\n",
       "13691    playin'   9.721176\n",
       "13692    blended   9.721176\n",
       "\n",
       "[2085 rows x 2 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>idf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1.126528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just</td>\n",
       "      <td>2.588812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm</td>\n",
       "      <td>2.645649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>3.015945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>3.113850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  idf_score\n",
       "0         1.126528\n",
       "1  just   2.588812\n",
       "2   i'm   2.645649\n",
       "3  good   3.015945\n",
       "4  like   3.113850"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grading cell do not modify\n",
    "display(most_imp_idf)\n",
    "display(least_imp_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ak3qte3tzlDt"
   },
   "source": [
    "Your explanation here: \n",
    "\n",
    "IDF scores represent the inverse document frequency for words in the corpus. \n",
    "I married the vocabularies that were treated as input data for tf-idf process with each of its idf score.\n",
    "Therefore, for the most_imp_idf dataframe, the words that are most frequently shown will be penalized with lower scores. \n",
    "For the least_imp_idf dataframe, the words that are least frequently shown will have higher scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYx3paKJxRF6"
   },
   "source": [
    "# Question 4: (10 pts)\n",
    "Create a new recursive pipeline named `lr_pipe` which starts with `tweets_pre_proc_pipe` and adds a logistic regression model using default hyper parameters.  Fit lr_pipe using `tweets_df`.  Score the model using ROC AUC.  Report the resulting AUC such that it is easy for graders to find and interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LdlAWWDJxRF7",
    "outputId": "97722aa0-4532-4a3d-f146-14d89a1955c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation (area under ROC): 0.720101\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "training, validation, test = tweets_df.randomSplit([0.6, 0.3, 0.1], 0)\n",
    "\n",
    "lr = LogisticRegression(labelCol = 'target',featuresCol='tfidf')\n",
    "\n",
    "#Create pipeline\n",
    "lr_pipe = Pipeline(stages=[tweets_pre_proc_pipe, lr])\n",
    "# Fit Model with training\n",
    "lr_model = lr_pipe.fit(training)\n",
    "\n",
    "# Compute raw scores on the test set\n",
    "prediction = lr_model.transform(test)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='target', rawPredictionCol=\"prediction\")\n",
    "evaluation = evaluator.evaluate(prediction)\n",
    "print(\"evaluation (area under ROC): %f\" % evaluation)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_j3dD6ZxRF9"
   },
   "source": [
    "# Question 5: (10 pts)\n",
    "Create 2 pandas dataframes named `lr_pipe_df_neg` and `lr_pipe_df_pos`which contain 2 colunms: `word` and `score`.  Load the 2 dataframes with the top 10 words and logistic regression coefficients that contribute the most to negative and positive sentiments respectively. Analyze the 2 dataframes and describe if the words make sense.  Do the words look like they are really negative and positive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "yGzlpXUoxRF9",
    "outputId": "28d2f482-5efd-4b24-822f-7cf8ef2d669f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of word: 9240\n",
      "length of weights: 9240\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "word = lr_model.stages[0].stages[-2].vocabulary\n",
    "weights = lr_model.stages[-1].coefficients.toArray()\n",
    "print('length of word:', len(word))\n",
    "print('length of weights:', len(weights))\n",
    "word_weights_df = pd.DataFrame({'word': word, 'score': weights})\n",
    "word_weights_df.head()\n",
    "\n",
    "lr_pipe_df_neg = word_weights_df.sort_values('score').head(10)\n",
    "lr_pipe_df_pos = word_weights_df.sort_values('score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "id": "xyc_LRaCxRGA",
    "outputId": "50be8bed-45bf-470c-afe5-ddcd714dbad2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>grr.</td>\n",
       "      <td>-4.248248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8897</th>\n",
       "      <td>stupidly</td>\n",
       "      <td>-3.792250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8824</th>\n",
       "      <td>tidying</td>\n",
       "      <td>-3.498210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8539</th>\n",
       "      <td>round.</td>\n",
       "      <td>-3.359560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>gutted!</td>\n",
       "      <td>-3.198066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8753</th>\n",
       "      <td>internet,</td>\n",
       "      <td>-3.147051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>depressed</td>\n",
       "      <td>-2.975052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8084</th>\n",
       "      <td>unlucky</td>\n",
       "      <td>-2.971917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>noo</td>\n",
       "      <td>-2.943008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>news:</td>\n",
       "      <td>-2.762037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word     score\n",
       "7868       grr. -4.248248\n",
       "8897   stupidly -3.792250\n",
       "8824    tidying -3.498210\n",
       "8539     round. -3.359560\n",
       "7838    gutted! -3.198066\n",
       "8753  internet, -3.147051\n",
       "2104  depressed -2.975052\n",
       "8084    unlucky -2.971917\n",
       "4772        noo -2.943008\n",
       "5549      news: -2.762037"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>thx!</td>\n",
       "      <td>3.886612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8749</th>\n",
       "      <td>andrew</td>\n",
       "      <td>3.775713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8870</th>\n",
       "      <td>tweeps,</td>\n",
       "      <td>3.590758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>here:</td>\n",
       "      <td>3.527108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>sane</td>\n",
       "      <td>2.959482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5785</th>\n",
       "      <td>smile.</td>\n",
       "      <td>2.812721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827</th>\n",
       "      <td>stones</td>\n",
       "      <td>2.691826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>thankyou</td>\n",
       "      <td>2.667729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>tip</td>\n",
       "      <td>2.623902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335</th>\n",
       "      <td>peaceful</td>\n",
       "      <td>2.606344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word     score\n",
       "5268      thx!  3.886612\n",
       "8749    andrew  3.775713\n",
       "8870   tweeps,  3.590758\n",
       "4180     here:  3.527108\n",
       "8141      sane  2.959482\n",
       "5785    smile.  2.812721\n",
       "8827    stones  2.691826\n",
       "2210  thankyou  2.667729\n",
       "3005       tip  2.623902\n",
       "5335  peaceful  2.606344"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grading cell - do not modify\n",
    "display(lr_pipe_df_neg)\n",
    "display(lr_pipe_df_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwYVSy7ZxRGC"
   },
   "source": [
    "Your explanation here: \n",
    "\n",
    "Looking into both dataframes, I am seeing a lot of model noises from both dataframes. The data does not display positive or negative sentiment and this is due to model overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pRQHjP1xRGD"
   },
   "source": [
    "# Question 6a: (5 pts)\n",
    "The goal of this question is to try to improve the score from question 4 using a regularization grid search on a new pipeline named `lr_pipe_1`. lr_pipe_1 is the same as lr_pipe above but we would like you to create a new pipe for grading purposes only.  I'm not sure if it's possible to increase the score or not.  You will be graded on level of effort to increase the score in relation to other students in the class.  All of your grid search code should be inside the `if enable_grid` statement in the cell below.  The enable_grid boolean is set to true in a grading cell above.  If any of the grid search code executes outside of the if statement, you will not get full credit for the question.  We want the ability to turn off the grid search during grading.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "fmZ_v8uFxRGD",
    "outputId": "d2ba1ef3-7122-4b93-a5e2-45cdb6c6c48b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score from new cv model:0.745523\n"
     ]
    }
   ],
   "source": [
    "# your grid search (and only your grid search) code here\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "lr_6a = LogisticRegression().\\\n",
    "        setLabelCol('target').\\\n",
    "        setFeaturesCol('tfidf').\\\n",
    "        setRegParam(0.0).\\\n",
    "        setMaxIter(100).\\\n",
    "        setElasticNetParam(0.)\n",
    "\n",
    "\n",
    "#lr_6a = LogisticRegression(labelCol = 'target',featuresCol='tfidf', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "if enable_grid:\n",
    "    # your grid search code here\n",
    "    #paramGrid = ParamGridBuilder().build()\n",
    "    grid = ParamGridBuilder().\\\n",
    "    addGrid(lr_6a.regParam, [0., 0.01, 0.02]).\\\n",
    "    addGrid(lr_6a.elasticNetParam, [0., 0.2, 0.3]).\\\n",
    "    build()\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(labelCol='target', rawPredictionCol=\"prediction\")\n",
    "    lr_pipe_1 = Pipeline(stages=[tweets_pre_proc_pipe, lr_6a])\n",
    "    cv_6a = CrossValidator(estimator=lr_pipe_1, evaluator=evaluator, estimatorParamMaps=grid, numFolds=3)\n",
    "    model_6a =cv_6a.fit(training)\n",
    "    prediction_6a = model_6a.transform(test)\n",
    "    pass\n",
    "\n",
    "# new_pred = new_prediction.toPandas()\n",
    "# new_pred.head()\n",
    "\n",
    "print('AUC score from new cv model:{:4f}'.format(evaluator.evaluate(prediction_6a)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gg7HSUGWxRGG"
   },
   "source": [
    "# Question 6b (5 pts)\n",
    "Build a new pipeline named `lr_pipe_2` which uses the optimized model parameters from the grid search in question 6a above (the best model).  Create 2 variables named alpha and lambda and assign to them the best alpha and lambda produced by the grid search by hard coding the values. Fit and transform lr_pipe_2.  Compare AUC scores between lr_pipe_2 with lr_pipe in question 4.  Create a pandas dataframe named `comapre_1_df` which encapsulates the comparison data.  comapre_1_df Shall have 2 columns: `model_name` and `auc_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "ZKp6L0a6xRGG",
    "outputId": "2c83a43e-f1f3-404d-e400-7981847bb5ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1\n",
      "Fitting model 2\n",
      "Fitting model 3\n",
      "Fitting model 4\n",
      "Fitting model 5\n",
      "Fitting model 6\n",
      "Fitting model 7\n",
      "Fitting model 8\n",
      "Fitting model 9\n",
      "best model index = 4\n"
     ]
    }
   ],
   "source": [
    "# your optimized model code here\n",
    "import numpy as np\n",
    "\n",
    "all_models = []\n",
    "for j in range(len(grid)):\n",
    "    print(\"Fitting model {}\".format(j+1))\n",
    "    model = lr_pipe_1.fit(training, grid[j])\n",
    "    all_models.append(model)\n",
    "\n",
    "accuracies = [m.\\\n",
    "    transform(validation).\\\n",
    "    select(fn.avg(fn.expr('float(target = prediction)')).alias('accuracy')).\\\n",
    "    first().\\\n",
    "    accuracy for m in all_models]\n",
    "\n",
    "best_model_idx = np.argmax(accuracies)\n",
    "print(\"best model index =\", best_model_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "A_1g3YZMxRGI",
    "outputId": "befff5b4-e2d7-4b1b-f10c-c54d2620413e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_efa156157426', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2,\n",
       " Param(parent='LogisticRegression_efa156157426', name='regParam', doc='regularization parameter (>= 0).'): 0.01}"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid[best_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "pi1BvfKqxRGK",
    "outputId": "3dd8a2ae-fac5-46e5-d30d-97959bb4451c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score from new cv model:0.745523\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_pipe</td>\n",
       "      <td>0.720101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_pipe_2</td>\n",
       "      <td>0.745523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  auc_score\n",
       "0    lr_pipe   0.720101\n",
       "1  lr_pipe_2   0.745523"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "# alpha = 0.1\n",
    "# lambda = 0.1\n",
    "\n",
    "# The following lambda and alpha parameter comes from the interpretation of printed output from grid[best_model_idx]\n",
    "lambda_par = 0.01\n",
    "alpha_par = 0.2\n",
    "lr_6b = LogisticRegression().\\\n",
    "        setLabelCol('target').\\\n",
    "        setFeaturesCol('tfidf').\\\n",
    "        setRegParam(lambda_par).\\\n",
    "        setMaxIter(100).\\\n",
    "        setElasticNetParam(alpha_par)\n",
    "\n",
    "\n",
    "# lr_pipe_2 code here\n",
    "#paramGrid = ParamGridBuilder().build()\n",
    "lr_pipe_2 = Pipeline(stages=[tweets_pre_proc_pipe, lr_6b])\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='target', rawPredictionCol=\"prediction\")\n",
    "model_6b =lr_pipe_2.fit(training)\n",
    "prediction_6b = model_6b.transform(test)\n",
    "\n",
    "print('AUC score from new cv model:{:4f}'.format(evaluator.evaluate(prediction_6b)))\n",
    "\n",
    "model_name = ['lr_pipe', 'lr_pipe_2']\n",
    "auc_score = [evaluator.evaluate(prediction), evaluator.evaluate(prediction_6b)]\n",
    "\n",
    "comapre_1_df = pd.DataFrame({'model_name': model_name, 'auc_score': auc_score})\n",
    "comapre_1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "3cDJ4rthxRGM",
    "outputId": "b204f286-cbb8-488d-abff-646ae9d63c03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_pipe</td>\n",
       "      <td>0.720101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_pipe_2</td>\n",
       "      <td>0.745523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  auc_score\n",
       "0    lr_pipe   0.720101\n",
       "1  lr_pipe_2   0.745523"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grading cell - do not modify\n",
    "display(comapre_1_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxRn2bSVxRGP"
   },
   "source": [
    "# Question 7 (10 pts)\n",
    "Perform inference on lr_pipe_2.  Write code to report how many words were eliminated from the best model in question 6b above (if any) as compared to the model in question 4 above.  Make sure your output is easy for the graders to find and interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "fFbI2EhzxRGP",
    "outputId": "61514207-5912-44dc-cbf6-00b99266d6c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of previous word: 9240\n",
      "length of updated word: 9240\n",
      "\n",
      " After comparsion, we can infer that no word has been deleted during the process of model optimization.\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Question 4 Original Model: Words & Weights\n",
    "word = lr_model.stages[0].stages[-2].vocabulary\n",
    "weights = lr_model.stages[-1].coefficients.toArray()\n",
    "\n",
    "# Question 7 Updated Model: Words & Weights\n",
    "word_6b = model_6b.stages[0].stages[-2].vocabulary\n",
    "weights_6b = model_6b.stages[-1].coefficients.toArray()\n",
    "print('length of previous word:', len(word))\n",
    "print('length of updated word:', len(word_6b))\n",
    "#print('length of updated weights:', len(weights_6b))\n",
    "print('\\n After comparsion, we can infer that no word has been deleted during the process of model optimization.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xr4Wj-jJxRGT"
   },
   "source": [
    "# Question 8 (10 pts)\n",
    "Perform the same inference analysis that you did in question 5 but name the data frames `lr_pipe_df_neg_1` and `lr_pipe_df_pos_1`.  Compare the word importance results with the results in question 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "id": "9Se-INlixRGT",
    "outputId": "c769dc37-0c7c-4c09-88ce-1765ad720fff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>sad</td>\n",
       "      <td>-0.504700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>poor</td>\n",
       "      <td>-0.355732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>miss</td>\n",
       "      <td>-0.354379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>wish</td>\n",
       "      <td>-0.350512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>missing</td>\n",
       "      <td>-0.346022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>hurts</td>\n",
       "      <td>-0.342330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>sick</td>\n",
       "      <td>-0.340919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>sucks</td>\n",
       "      <td>-0.336293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>lonely</td>\n",
       "      <td>-0.321246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>sad.</td>\n",
       "      <td>-0.314775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word     score\n",
       "54       sad -0.504700\n",
       "182     poor -0.355732\n",
       "35      miss -0.354379\n",
       "37      wish -0.350512\n",
       "162  missing -0.346022\n",
       "302    hurts -0.342330\n",
       "94      sick -0.340919\n",
       "249    sucks -0.336293\n",
       "592   lonely -0.321246\n",
       "582     sad. -0.314775"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>thanks</td>\n",
       "      <td>0.328314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>thank</td>\n",
       "      <td>0.305772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>welcome</td>\n",
       "      <td>0.301187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>peaceful</td>\n",
       "      <td>0.258743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>0.250217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>proud</td>\n",
       "      <td>0.240826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.239985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>blessed</td>\n",
       "      <td>0.239330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>post.</td>\n",
       "      <td>0.237532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>glad</td>\n",
       "      <td>0.227573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word     score\n",
       "29      thanks  0.328314\n",
       "70       thank  0.305772\n",
       "224    welcome  0.301187\n",
       "5039  peaceful  0.258743\n",
       "3         good  0.250217\n",
       "1045     proud  0.240826\n",
       "46       happy  0.239985\n",
       "1587   blessed  0.239330\n",
       "4016     post.  0.237532\n",
       "111       glad  0.227573"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "word_weights_df_1 = pd.DataFrame({'word': word_6b, 'score': weights_6b})\n",
    "word_weights_df_1.head()\n",
    "\n",
    "lr_pipe_df_neg_1 = word_weights_df_1.sort_values('score').head(10)\n",
    "lr_pipe_df_pos_1 = word_weights_df_1.sort_values('score', ascending=False).head(10)\n",
    "\n",
    "display(lr_pipe_df_neg_1)\n",
    "display(lr_pipe_df_pos_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "id": "NiMr0gczxRGV",
    "outputId": "131eaf24-9fd9-4ed8-a1af-8c4c42be6ff6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>sad</td>\n",
       "      <td>-0.504700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>poor</td>\n",
       "      <td>-0.355732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>miss</td>\n",
       "      <td>-0.354379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>wish</td>\n",
       "      <td>-0.350512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>missing</td>\n",
       "      <td>-0.346022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>hurts</td>\n",
       "      <td>-0.342330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>sick</td>\n",
       "      <td>-0.340919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>sucks</td>\n",
       "      <td>-0.336293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>lonely</td>\n",
       "      <td>-0.321246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>sad.</td>\n",
       "      <td>-0.314775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word     score\n",
       "54       sad -0.504700\n",
       "182     poor -0.355732\n",
       "35      miss -0.354379\n",
       "37      wish -0.350512\n",
       "162  missing -0.346022\n",
       "302    hurts -0.342330\n",
       "94      sick -0.340919\n",
       "249    sucks -0.336293\n",
       "592   lonely -0.321246\n",
       "582     sad. -0.314775"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>thanks</td>\n",
       "      <td>0.328314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>thank</td>\n",
       "      <td>0.305772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>welcome</td>\n",
       "      <td>0.301187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>peaceful</td>\n",
       "      <td>0.258743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>0.250217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>proud</td>\n",
       "      <td>0.240826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.239985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>blessed</td>\n",
       "      <td>0.239330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>post.</td>\n",
       "      <td>0.237532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>glad</td>\n",
       "      <td>0.227573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word     score\n",
       "29      thanks  0.328314\n",
       "70       thank  0.305772\n",
       "224    welcome  0.301187\n",
       "5039  peaceful  0.258743\n",
       "3         good  0.250217\n",
       "1045     proud  0.240826\n",
       "46       happy  0.239985\n",
       "1587   blessed  0.239330\n",
       "4016     post.  0.237532\n",
       "111       glad  0.227573"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grading cell - do not modify\n",
    "display(lr_pipe_df_neg_1)\n",
    "display(lr_pipe_df_pos_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lhr8gCv3xRGX"
   },
   "source": [
    "##### Grading Feedback Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOm1OQUyxRGY"
   },
   "source": [
    "Your explanation here:\n",
    "    \n",
    "The result I obtained from question 8 peforms better than that from question 5. \n",
    "As we examined both dataframes that showcase most negative and most positive words,\n",
    "negative words such as \"sad\", \"poor\" and \"sadly\" etc. reflect negative sentiment with mitigated level of noises.\n",
    "This is the same for the words from positive sentiment dataframe.\n",
    "Another notable difference is that the weights for each word is significantly small,\n",
    "and this could come from a combination of cross validation model and regularization net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwgTgK2yxRGY"
   },
   "source": [
    "# Question 9 (10 pts)\n",
    "Create a receiver operating characteristic (ROC) plot for the best model in question 6.  Briefly describe in words the high level steps needed to build a ROC curve as outlined in lecture.  Convince me you understand the high level steps needed to make a ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "b1jxQaBtxRGZ",
    "outputId": "0d2be77f-5a6f-42b5-dc5c-1116076b5a98"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot([0, 1], [0, 1], 'r--', label = 'No Skill')\n",
    "number = model_6b.stages[-1].summary.roc.toPandas()\n",
    "FPR,TPR = number['FPR'],number['TPR']\n",
    "\n",
    "plt.plot(FPR, TPR, label='Logistic Regression')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Kh48BxW2_3o"
   },
   "source": [
    "Your explanation here:\n",
    "\n",
    "The reason why we are using ROC curve to assess our model is because logistic regression is a binary classification model\n",
    "and ROC curve is a suitable evaluation metric to use in this situation. We utilized this curve to assess how well our model \n",
    "predicts the positive/negative sentiment of a tweet. In order to plot a ROC curve, we need to obtain TPR (True Positive Rate)\n",
    "against FPR (False Positive Rate). The area under the curve (blue line) showcases the regression model's prediction ability. \n",
    "The greater the AUC value, the better the model's predicting ability is. \n",
    "When AUC is 0.5 (the red line in graph), this means that model has no class separation capacity.\n",
    "\n",
    "For the FPR value, we can obtain it from (FP/(FP+FN)) and these values can be found in confusion matrix. This means, out of all negative values, \n",
    "FPR represent the percentage of predicting the wrong negative value. For the TPR value, we can obtain it from (TP/(TP+FN)). \n",
    "Out of all positive values, this metric showcases the percentage of correctly predicting the values as positive.\n",
    "\n",
    "Smaller values on the x-axis of the plot indicate lower false positives and higher true negatives. Larger values on the y-axis of the plot indicate higher true positives and lower false negatives.\n",
    "For my ROC curve, the curve shows that my logistic regression did a good job at assign a higher probability to a randomly chosen real positive occurrence than a negative occurrence on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvoThpnbxRGd"
   },
   "source": [
    "# Question 10 (10 pts)\n",
    "Learn about [precision/recall](https://en.wikipedia.org/wiki/Precision_and_recall) curves. Using the logistic regression summary object contained in the linear regression object within lr_pipe_2, create a precision recall plot. Similar to the `roc` object which is available in the logistic regression summary, there is a `pr` object which can be used to help create a precision / recall curve.  Note that the precision recall curve is built using the same high level methodology as the ROC curve, but using different metrics calculated from the confusion matrix.  If you understand how a ROC curve is built, you understand how a precision / recall curve is built.  Compare and contrast the differences between precision / recall and ROC curves.  What axis is common and what axis is different between the 2 curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "c42ti-CTxRGe",
    "outputId": "b9c0e9b9-35cb-49f4-9b0d-c356df021e5c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# plt.figure(figsize=(5,5))\n",
    "# plt.plot([0, 1], [0, 1], 'r--')\n",
    "number = model_6b.stages[-1].summary.pr.toPandas()\n",
    "number.head()\n",
    "recall,precision = number['recall'],number['precision']\n",
    "\n",
    "plt.plot(recall, precision, label='Logistic Regression')\n",
    "plt.plot([0, 1], [0.5, 0.5], linestyle='--', label='No Skill')\n",
    "plt.title('Precision/Recall curves')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuN7ulDA26M-"
   },
   "source": [
    "Your explanation here:\n",
    "\n",
    "A precision-recall curve is a plot of the precision (y-axis) and the recall (x-axis) for different thresholds and it\n",
    "is another evaluation metric we used to assess the performance of the binary classification models. \n",
    "Precision is the ratio of the true positive divided by the sum of true positive and false negative values. \n",
    "Precision shows how good a model predict positive class. Recall is also called sensitivity. \n",
    "It is the ratio of the true positives divided by the sum of true positives and false negatives.\n",
    "\n",
    "We more often observe precision-recall curve than ROC curve when there is an inbalanced dataset being used as input data. \n",
    "While the baseline is fixed with ROC, the baseline of [precision-recall curve] is determined by the ratio \n",
    "of positives and negatives as y = P / (P + N).\n",
    "\n",
    "To answer the question from question 10, \n",
    "the recall axis (x-axis) from precision/recall curve is the same as the TPR axis (y-axis) from the ROC curve.\n",
    "\n",
    "However, the FPR axis is different from the precision axis because precision axis focus on the model's ability to \n",
    "correctly predict positive cases.\n",
    "\n",
    "TPR = TP/(TP+FN)\n",
    "FPR = FP/(FP+FN)\n",
    "precision = TP/ (TP + FP)\n",
    "recall = TP/(TP + FN)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IST-718 Fall 2020 Homework 4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
